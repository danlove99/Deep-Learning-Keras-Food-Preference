{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KerasFoodPreference.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOiqpYJcpI5ND7C/P4oOQQa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YCQHvOtST_Sy","colab_type":"code","colab":{}},"source":["from numpy import loadtxt \n","from keras.models import Sequential\n","from keras.layers import Dense\n","import urllib.request"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTcpmfjYUA1R","colab_type":"code","colab":{}},"source":["# load the dataset\n","url = 'https://raw.githubusercontent.com/danlove99/Deep-Learning-Keras-Food-Preference/master/Food.csv'\n","response = urllib.request.urlopen(url)\n","dataset = loadtxt(response, delimiter=',')\n","# split into input (X) and \n","# output (y) variables\n","X = dataset[:,0:18] \n","y = dataset[:,18]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XlaweKAFU2BC","colab_type":"code","outputId":"d82b3254-fccb-47c1-bf88-ad17b672fbf9","executionInfo":{"status":"ok","timestamp":1581598169126,"user_tz":0,"elapsed":495,"user":{"displayName":"dan love","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA1v95PeDFtoVw3PsBonT6znHltIxeAY7eTr6zqig=s64","userId":"00298714935061777271"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["# define the keras model\n","model = Sequential() \n","model.add(Dense(12, input_dim=18, activation='relu')) \n","model.add(Dense(8, activation='relu')) \n","model.add(Dense(1, activation='sigmoid'))\n","# compile the keras model\n","model.compile(loss='binary_crossentropy', \n","optimizer='adam', \n","metrics=['accuracy'])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5JuQjY9_U7hi","colab_type":"code","outputId":"428b5365-6b8f-4019-a00b-db788497340c","executionInfo":{"status":"ok","timestamp":1581598197293,"user_tz":0,"elapsed":25238,"user":{"displayName":"dan love","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA1v95PeDFtoVw3PsBonT6znHltIxeAY7eTr6zqig=s64","userId":"00298714935061777271"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# fit the keras model on the dataset\n","model.fit(X, y, epochs=150, batch_size=10)\n","# evaluate the keras model\n","_, accuracy = model.evaluate(X, y)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/150\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","288/288 [==============================] - 9s 33ms/step - loss: 0.4538 - acc: 0.8229\n","Epoch 2/150\n","288/288 [==============================] - 0s 330us/step - loss: 0.4369 - acc: 0.8264\n","Epoch 3/150\n","288/288 [==============================] - 0s 345us/step - loss: 0.4297 - acc: 0.8264\n","Epoch 4/150\n","288/288 [==============================] - 0s 349us/step - loss: 0.4251 - acc: 0.8264\n","Epoch 5/150\n","288/288 [==============================] - 0s 371us/step - loss: 0.4258 - acc: 0.8264\n","Epoch 6/150\n","288/288 [==============================] - 0s 341us/step - loss: 0.4277 - acc: 0.8264\n","Epoch 7/150\n","288/288 [==============================] - 0s 353us/step - loss: 0.4235 - acc: 0.8264\n","Epoch 8/150\n","288/288 [==============================] - 0s 377us/step - loss: 0.4294 - acc: 0.8264\n","Epoch 9/150\n","288/288 [==============================] - 0s 294us/step - loss: 0.4239 - acc: 0.8264\n","Epoch 10/150\n","288/288 [==============================] - 0s 335us/step - loss: 0.4228 - acc: 0.8264\n","Epoch 11/150\n","288/288 [==============================] - 0s 362us/step - loss: 0.4290 - acc: 0.8264\n","Epoch 12/150\n","288/288 [==============================] - 0s 321us/step - loss: 0.4254 - acc: 0.8264\n","Epoch 13/150\n","288/288 [==============================] - 0s 336us/step - loss: 0.4224 - acc: 0.8264\n","Epoch 14/150\n","288/288 [==============================] - 0s 324us/step - loss: 0.4213 - acc: 0.8264\n","Epoch 15/150\n","288/288 [==============================] - 0s 324us/step - loss: 0.4245 - acc: 0.8264\n","Epoch 16/150\n","288/288 [==============================] - 0s 357us/step - loss: 0.4228 - acc: 0.8264\n","Epoch 17/150\n","288/288 [==============================] - 0s 372us/step - loss: 0.4262 - acc: 0.8264\n","Epoch 18/150\n","288/288 [==============================] - 0s 359us/step - loss: 0.4210 - acc: 0.8264\n","Epoch 19/150\n","288/288 [==============================] - 0s 382us/step - loss: 0.4293 - acc: 0.8264\n","Epoch 20/150\n","288/288 [==============================] - 0s 329us/step - loss: 0.4300 - acc: 0.8264\n","Epoch 21/150\n","288/288 [==============================] - 0s 345us/step - loss: 0.4216 - acc: 0.8264\n","Epoch 22/150\n","288/288 [==============================] - 0s 314us/step - loss: 0.4234 - acc: 0.8264\n","Epoch 23/150\n","288/288 [==============================] - 0s 343us/step - loss: 0.4216 - acc: 0.8264\n","Epoch 24/150\n","288/288 [==============================] - 0s 321us/step - loss: 0.4200 - acc: 0.8264\n","Epoch 25/150\n","288/288 [==============================] - 0s 328us/step - loss: 0.4210 - acc: 0.8264\n","Epoch 26/150\n","288/288 [==============================] - 0s 321us/step - loss: 0.4186 - acc: 0.8264\n","Epoch 27/150\n","288/288 [==============================] - 0s 353us/step - loss: 0.4204 - acc: 0.8264\n","Epoch 28/150\n","288/288 [==============================] - 0s 332us/step - loss: 0.4192 - acc: 0.8264\n","Epoch 29/150\n","288/288 [==============================] - 0s 371us/step - loss: 0.4188 - acc: 0.8264\n","Epoch 30/150\n","288/288 [==============================] - 0s 341us/step - loss: 0.4175 - acc: 0.8264\n","Epoch 31/150\n","288/288 [==============================] - 0s 330us/step - loss: 0.4268 - acc: 0.8264\n","Epoch 32/150\n","288/288 [==============================] - 0s 325us/step - loss: 0.4183 - acc: 0.8264\n","Epoch 33/150\n","288/288 [==============================] - 0s 320us/step - loss: 0.4149 - acc: 0.8264\n","Epoch 34/150\n","288/288 [==============================] - 0s 325us/step - loss: 0.4164 - acc: 0.8264\n","Epoch 35/150\n","288/288 [==============================] - 0s 307us/step - loss: 0.4276 - acc: 0.8264\n","Epoch 36/150\n","288/288 [==============================] - 0s 315us/step - loss: 0.4323 - acc: 0.8264\n","Epoch 37/150\n","288/288 [==============================] - 0s 309us/step - loss: 0.4136 - acc: 0.8264\n","Epoch 38/150\n","288/288 [==============================] - 0s 340us/step - loss: 0.4189 - acc: 0.8264\n","Epoch 39/150\n","288/288 [==============================] - 0s 339us/step - loss: 0.4193 - acc: 0.8264\n","Epoch 40/150\n","288/288 [==============================] - 0s 375us/step - loss: 0.4142 - acc: 0.8264\n","Epoch 41/150\n","288/288 [==============================] - 0s 331us/step - loss: 0.4208 - acc: 0.8264\n","Epoch 42/150\n","288/288 [==============================] - 0s 365us/step - loss: 0.4150 - acc: 0.8264\n","Epoch 43/150\n","288/288 [==============================] - 0s 336us/step - loss: 0.4148 - acc: 0.8194\n","Epoch 44/150\n","288/288 [==============================] - 0s 367us/step - loss: 0.4173 - acc: 0.8264\n","Epoch 45/150\n","288/288 [==============================] - 0s 312us/step - loss: 0.4164 - acc: 0.8264\n","Epoch 46/150\n","288/288 [==============================] - 0s 301us/step - loss: 0.4119 - acc: 0.8299\n","Epoch 47/150\n","288/288 [==============================] - 0s 317us/step - loss: 0.4142 - acc: 0.8264\n","Epoch 48/150\n","288/288 [==============================] - 0s 368us/step - loss: 0.4175 - acc: 0.8229\n","Epoch 49/150\n","288/288 [==============================] - 0s 347us/step - loss: 0.4157 - acc: 0.8264\n","Epoch 50/150\n","288/288 [==============================] - 0s 380us/step - loss: 0.4124 - acc: 0.8229\n","Epoch 51/150\n","288/288 [==============================] - 0s 315us/step - loss: 0.4143 - acc: 0.8229\n","Epoch 52/150\n","288/288 [==============================] - 0s 362us/step - loss: 0.4117 - acc: 0.8264\n","Epoch 53/150\n","288/288 [==============================] - 0s 353us/step - loss: 0.4167 - acc: 0.8264\n","Epoch 54/150\n","288/288 [==============================] - 0s 372us/step - loss: 0.4101 - acc: 0.8229\n","Epoch 55/150\n","288/288 [==============================] - 0s 367us/step - loss: 0.4114 - acc: 0.8264\n","Epoch 56/150\n","288/288 [==============================] - 0s 364us/step - loss: 0.4096 - acc: 0.8229\n","Epoch 57/150\n","288/288 [==============================] - 0s 344us/step - loss: 0.4104 - acc: 0.8229\n","Epoch 58/150\n","288/288 [==============================] - 0s 336us/step - loss: 0.4174 - acc: 0.8229\n","Epoch 59/150\n","288/288 [==============================] - 0s 350us/step - loss: 0.4104 - acc: 0.8229\n","Epoch 60/150\n","288/288 [==============================] - 0s 367us/step - loss: 0.4153 - acc: 0.8229\n","Epoch 61/150\n","288/288 [==============================] - 0s 376us/step - loss: 0.4093 - acc: 0.8194\n","Epoch 62/150\n","288/288 [==============================] - 0s 338us/step - loss: 0.4102 - acc: 0.8194\n","Epoch 63/150\n","288/288 [==============================] - 0s 356us/step - loss: 0.4160 - acc: 0.8194\n","Epoch 64/150\n","288/288 [==============================] - 0s 322us/step - loss: 0.4145 - acc: 0.8264\n","Epoch 65/150\n","288/288 [==============================] - 0s 342us/step - loss: 0.4124 - acc: 0.8264\n","Epoch 66/150\n","288/288 [==============================] - 0s 321us/step - loss: 0.4119 - acc: 0.8229\n","Epoch 67/150\n","288/288 [==============================] - 0s 363us/step - loss: 0.4090 - acc: 0.8229\n","Epoch 68/150\n","288/288 [==============================] - 0s 359us/step - loss: 0.4107 - acc: 0.8194\n","Epoch 69/150\n","288/288 [==============================] - 0s 417us/step - loss: 0.4232 - acc: 0.8194\n","Epoch 70/150\n","288/288 [==============================] - 0s 461us/step - loss: 0.4135 - acc: 0.8194\n","Epoch 71/150\n","288/288 [==============================] - 0s 397us/step - loss: 0.4214 - acc: 0.8264\n","Epoch 72/150\n","288/288 [==============================] - 0s 432us/step - loss: 0.4175 - acc: 0.8229\n","Epoch 73/150\n","288/288 [==============================] - 0s 371us/step - loss: 0.4052 - acc: 0.8229\n","Epoch 74/150\n","288/288 [==============================] - 0s 373us/step - loss: 0.4062 - acc: 0.8229\n","Epoch 75/150\n","288/288 [==============================] - 0s 355us/step - loss: 0.4106 - acc: 0.8229\n","Epoch 76/150\n","288/288 [==============================] - 0s 339us/step - loss: 0.4096 - acc: 0.8229\n","Epoch 77/150\n","288/288 [==============================] - 0s 339us/step - loss: 0.4100 - acc: 0.8229\n","Epoch 78/150\n","288/288 [==============================] - 0s 355us/step - loss: 0.4073 - acc: 0.8229\n","Epoch 79/150\n","288/288 [==============================] - 0s 373us/step - loss: 0.4116 - acc: 0.8229\n","Epoch 80/150\n","288/288 [==============================] - 0s 397us/step - loss: 0.4113 - acc: 0.8194\n","Epoch 81/150\n","288/288 [==============================] - 0s 371us/step - loss: 0.4051 - acc: 0.8229\n","Epoch 82/150\n","288/288 [==============================] - 0s 352us/step - loss: 0.4073 - acc: 0.8299\n","Epoch 83/150\n","288/288 [==============================] - 0s 338us/step - loss: 0.4080 - acc: 0.8194\n","Epoch 84/150\n","288/288 [==============================] - 0s 347us/step - loss: 0.4038 - acc: 0.8229\n","Epoch 85/150\n","288/288 [==============================] - 0s 372us/step - loss: 0.4047 - acc: 0.8229\n","Epoch 86/150\n","288/288 [==============================] - 0s 341us/step - loss: 0.4100 - acc: 0.8194\n","Epoch 87/150\n","288/288 [==============================] - 0s 382us/step - loss: 0.4047 - acc: 0.8299\n","Epoch 88/150\n","288/288 [==============================] - 0s 324us/step - loss: 0.4111 - acc: 0.8299\n","Epoch 89/150\n","288/288 [==============================] - 0s 372us/step - loss: 0.4060 - acc: 0.8264\n","Epoch 90/150\n","288/288 [==============================] - 0s 345us/step - loss: 0.4039 - acc: 0.8229\n","Epoch 91/150\n","288/288 [==============================] - 0s 359us/step - loss: 0.4033 - acc: 0.8264\n","Epoch 92/150\n","288/288 [==============================] - 0s 323us/step - loss: 0.4028 - acc: 0.8229\n","Epoch 93/150\n","288/288 [==============================] - 0s 349us/step - loss: 0.4041 - acc: 0.8194\n","Epoch 94/150\n","288/288 [==============================] - 0s 321us/step - loss: 0.4022 - acc: 0.8229\n","Epoch 95/150\n","288/288 [==============================] - 0s 351us/step - loss: 0.4028 - acc: 0.8194\n","Epoch 96/150\n","288/288 [==============================] - 0s 334us/step - loss: 0.4017 - acc: 0.8194\n","Epoch 97/150\n","288/288 [==============================] - 0s 360us/step - loss: 0.4071 - acc: 0.8229\n","Epoch 98/150\n","288/288 [==============================] - 0s 307us/step - loss: 0.4050 - acc: 0.8229\n","Epoch 99/150\n","288/288 [==============================] - 0s 432us/step - loss: 0.4012 - acc: 0.8264\n","Epoch 100/150\n","288/288 [==============================] - 0s 344us/step - loss: 0.4017 - acc: 0.8229\n","Epoch 101/150\n","288/288 [==============================] - 0s 321us/step - loss: 0.4035 - acc: 0.8194\n","Epoch 102/150\n","288/288 [==============================] - 0s 334us/step - loss: 0.4037 - acc: 0.8194\n","Epoch 103/150\n","288/288 [==============================] - 0s 305us/step - loss: 0.4013 - acc: 0.8194\n","Epoch 104/150\n","288/288 [==============================] - 0s 308us/step - loss: 0.4024 - acc: 0.8229\n","Epoch 105/150\n","288/288 [==============================] - 0s 356us/step - loss: 0.4079 - acc: 0.8299\n","Epoch 106/150\n","288/288 [==============================] - 0s 340us/step - loss: 0.4033 - acc: 0.8229\n","Epoch 107/150\n","288/288 [==============================] - 0s 327us/step - loss: 0.4073 - acc: 0.8194\n","Epoch 108/150\n","288/288 [==============================] - 0s 298us/step - loss: 0.3992 - acc: 0.8299\n","Epoch 109/150\n","288/288 [==============================] - 0s 366us/step - loss: 0.4023 - acc: 0.8229\n","Epoch 110/150\n","288/288 [==============================] - 0s 343us/step - loss: 0.4051 - acc: 0.8264\n","Epoch 111/150\n","288/288 [==============================] - 0s 367us/step - loss: 0.4047 - acc: 0.8264\n","Epoch 112/150\n","288/288 [==============================] - 0s 299us/step - loss: 0.4012 - acc: 0.8229\n","Epoch 113/150\n","288/288 [==============================] - 0s 370us/step - loss: 0.4012 - acc: 0.8299\n","Epoch 114/150\n","288/288 [==============================] - 0s 351us/step - loss: 0.4004 - acc: 0.8299\n","Epoch 115/150\n","288/288 [==============================] - 0s 357us/step - loss: 0.4020 - acc: 0.8264\n","Epoch 116/150\n","288/288 [==============================] - 0s 356us/step - loss: 0.3998 - acc: 0.8333\n","Epoch 117/150\n","288/288 [==============================] - 0s 374us/step - loss: 0.3984 - acc: 0.8229\n","Epoch 118/150\n","288/288 [==============================] - 0s 419us/step - loss: 0.3994 - acc: 0.8299\n","Epoch 119/150\n","288/288 [==============================] - 0s 404us/step - loss: 0.4001 - acc: 0.8229\n","Epoch 120/150\n","288/288 [==============================] - 0s 399us/step - loss: 0.4006 - acc: 0.8264\n","Epoch 121/150\n","288/288 [==============================] - 0s 343us/step - loss: 0.3981 - acc: 0.8333\n","Epoch 122/150\n","288/288 [==============================] - 0s 324us/step - loss: 0.4012 - acc: 0.8264\n","Epoch 123/150\n","288/288 [==============================] - 0s 334us/step - loss: 0.4008 - acc: 0.8229\n","Epoch 124/150\n","288/288 [==============================] - 0s 346us/step - loss: 0.3975 - acc: 0.8229\n","Epoch 125/150\n","288/288 [==============================] - 0s 338us/step - loss: 0.3966 - acc: 0.8299\n","Epoch 126/150\n","288/288 [==============================] - 0s 344us/step - loss: 0.3975 - acc: 0.8299\n","Epoch 127/150\n","288/288 [==============================] - 0s 368us/step - loss: 0.3979 - acc: 0.8299\n","Epoch 128/150\n","288/288 [==============================] - 0s 379us/step - loss: 0.3994 - acc: 0.8299\n","Epoch 129/150\n","288/288 [==============================] - 0s 350us/step - loss: 0.4007 - acc: 0.8229\n","Epoch 130/150\n","288/288 [==============================] - 0s 357us/step - loss: 0.4002 - acc: 0.8299\n","Epoch 131/150\n","288/288 [==============================] - 0s 310us/step - loss: 0.3999 - acc: 0.8264\n","Epoch 132/150\n","288/288 [==============================] - 0s 320us/step - loss: 0.4031 - acc: 0.8299\n","Epoch 133/150\n","288/288 [==============================] - 0s 314us/step - loss: 0.4019 - acc: 0.8264\n","Epoch 134/150\n","288/288 [==============================] - 0s 353us/step - loss: 0.3976 - acc: 0.8194\n","Epoch 135/150\n","288/288 [==============================] - 0s 341us/step - loss: 0.3988 - acc: 0.8264\n","Epoch 136/150\n","288/288 [==============================] - 0s 378us/step - loss: 0.3944 - acc: 0.8229\n","Epoch 137/150\n","288/288 [==============================] - 0s 335us/step - loss: 0.3954 - acc: 0.8194\n","Epoch 138/150\n","288/288 [==============================] - 0s 333us/step - loss: 0.3986 - acc: 0.8264\n","Epoch 139/150\n","288/288 [==============================] - 0s 353us/step - loss: 0.4061 - acc: 0.8160\n","Epoch 140/150\n","288/288 [==============================] - 0s 369us/step - loss: 0.3999 - acc: 0.8264\n","Epoch 141/150\n","288/288 [==============================] - 0s 308us/step - loss: 0.3976 - acc: 0.8333\n","Epoch 142/150\n","288/288 [==============================] - 0s 367us/step - loss: 0.4049 - acc: 0.8264\n","Epoch 143/150\n","288/288 [==============================] - 0s 390us/step - loss: 0.4039 - acc: 0.8194\n","Epoch 144/150\n","288/288 [==============================] - 0s 350us/step - loss: 0.3963 - acc: 0.8299\n","Epoch 145/150\n","288/288 [==============================] - 0s 310us/step - loss: 0.3947 - acc: 0.8229\n","Epoch 146/150\n","288/288 [==============================] - 0s 333us/step - loss: 0.3953 - acc: 0.8264\n","Epoch 147/150\n","288/288 [==============================] - 0s 340us/step - loss: 0.3952 - acc: 0.8194\n","Epoch 148/150\n","288/288 [==============================] - 0s 327us/step - loss: 0.3949 - acc: 0.8264\n","Epoch 149/150\n","288/288 [==============================] - 0s 318us/step - loss: 0.3969 - acc: 0.8229\n","Epoch 150/150\n","288/288 [==============================] - 0s 327us/step - loss: 0.4029 - acc: 0.8333\n","288/288 [==============================] - 0s 142us/step\n","Accuracy: 83.33\n"],"name":"stdout"}]}]}